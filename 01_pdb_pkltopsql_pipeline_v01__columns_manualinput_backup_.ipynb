{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d7108f2-c982-4ba6-b028-33a4fea60e36",
   "metadata": {},
   "source": [
    "# Goal:\n",
    "- This code reads and converts .pkl data into table format\n",
    "- Create Database using postgreSQL\n",
    "- Exports from table as .pkl\n",
    "\n",
    "# Updates\n",
    "- Add a final “proof” comparator\n",
    "- Capture index during insert\n",
    "- Export using original order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789e483b-5106-4dd5-ad8c-fcb71233c7dd",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "- **postgreSQL** - Download and install it on your system\n",
    "- Download_Link -> https://www.postgresql.org/download/windows/\n",
    "- during installation - create and save superuser, pwd - which you need latter\n",
    "- **Python** > 3.9+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0158e09b-239c-43c2-ade2-f4123e2cbfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# STEP 0: Imports\n",
    "# =========================================\n",
    "import pickle\n",
    "import json\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# ---------------- CONFIG ---------------- #\n",
    "PKL_PATH = \"../data/ghazi/ENSG00000188938.pkl\"\n",
    "\n",
    "PG_USER = \"postgres\"\n",
    "PG_PASSWORD = \"manjoor123$ps\"\n",
    "PG_HOST = \"localhost\"\n",
    "PG_PORT = \"5432\"\n",
    "DB_NAME = \"protein_db_test7\"\n",
    "\n",
    "TABLE_NAME = \"protein_table_ensg00000188938_test7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dffa4712-55e4-476f-a9e1-611955c08df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total proteins: 5\n",
      "PDB files per protein: [810, 396, 779, 864, 802]\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# STEP 1: Load dataset\n",
    "# =========================================\n",
    "with open(PKL_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(\"Total proteins:\", len(data))\n",
    "print(\"PDB files per protein:\", [len(e.get(\"pdb_files\", [])) for e in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc4b5572-f74a-41f6-882a-f1bf17fbf4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'protein_db_test7' created.\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# STEP 2: Connect to DB (create if not exists)\n",
    "# =========================================\n",
    "# Admin connection to create DB\n",
    "admin_engine = create_engine(\n",
    "    f\"postgresql+psycopg2://{PG_USER}:{PG_PASSWORD}@{PG_HOST}:{PG_PORT}/postgres\",\n",
    "    isolation_level=\"AUTOCOMMIT\"\n",
    ")\n",
    "\n",
    "with admin_engine.connect() as conn:\n",
    "    result = conn.execute(\n",
    "        text(\"SELECT 1 FROM pg_database WHERE datname=:name\"), {\"name\": DB_NAME}\n",
    "    ).fetchone()\n",
    "    if not result:\n",
    "        conn.execute(text(f\"CREATE DATABASE {DB_NAME}\"))\n",
    "        print(f\"Database '{DB_NAME}' created.\")\n",
    "    else:\n",
    "        print(f\"Database '{DB_NAME}' already exists.\")\n",
    "\n",
    "# Connect to the target database\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://{PG_USER}:{PG_PASSWORD}@{PG_HOST}:{PG_PORT}/{DB_NAME}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78218a96-6bfa-4cea-baa3-0786211e154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'protein_table_ensg00000188938_test7' created or already exists.\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# STEP 3: Create table (single-table with BYTEA[])\n",
    "# =========================================\n",
    "create_table_sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {TABLE_NAME} (\n",
    "    gene_id VARCHAR(15) NOT NULL,\n",
    "    transcript_id VARCHAR(30) NOT NULL,\n",
    "    protein_index INTEGER NOT NULL,\n",
    "    sequence VARCHAR(400),\n",
    "    exons JSONB,\n",
    "    protein_coding BOOLEAN,\n",
    "    nmd BOOLEAN,\n",
    "    pdb_ids TEXT[],\n",
    "    pdb_files BYTEA[],\n",
    "    PRIMARY KEY (gene_id, transcript_id)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(create_table_sql))\n",
    "\n",
    "print(f\"Table '{TABLE_NAME}' created or already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2022cf-0dfd-4fe4-8b1c-39331cd38899",
   "metadata": {},
   "source": [
    "# Insert rows/proteins + PDBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e1ac221-860d-40ce-9a5f-88b2241efcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Inserted 5 proteins with 3651 total PDB files.\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# STEP 4: Insert proteins + PDBs\n",
    "# =========================================\n",
    "def insert_proteins_with_pdbs(engine, data, table_name):\n",
    "    \"\"\"\n",
    "    Insert proteins with PDB files into the database.\n",
    "    Preserves original PKL order using protein_index.\n",
    "    \"\"\"\n",
    "\n",
    "    sql = f\"\"\"\n",
    "    INSERT INTO {table_name} (\n",
    "        gene_id, transcript_id, protein_index,\n",
    "        sequence, exons, protein_coding, nmd,\n",
    "        pdb_ids, pdb_files\n",
    "    )\n",
    "    VALUES (\n",
    "        %(gene_id)s, %(transcript_id)s, %(protein_index)s,\n",
    "        %(sequence)s, %(exons)s, %(protein_coding)s, %(nmd)s,\n",
    "        %(pdb_ids)s, %(pdb_files)s\n",
    "    )\n",
    "    ON CONFLICT (gene_id, transcript_id) DO NOTHING;\n",
    "    \"\"\"\n",
    "\n",
    "    conn = engine.raw_connection()\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        total_pdbs = 0  # initialize PDB counter\n",
    "\n",
    "        for protein_index, entry in enumerate(data):\n",
    "            # Prepare PDB IDs and content\n",
    "            pdb_ids = [p[\"pdb_id\"] for p in entry.get(\"pdb_files\", [])]\n",
    "            pdb_files = [psycopg2.Binary(p[\"content\"]) for p in entry.get(\"pdb_files\", [])]\n",
    "\n",
    "            total_pdbs += len(pdb_files)  # count total PDBs\n",
    "\n",
    "            # Execute insert\n",
    "            cur.execute(sql, {\n",
    "                \"gene_id\": entry[\"gene_id\"],\n",
    "                \"transcript_id\": entry[\"transcript_id\"],\n",
    "                \"protein_index\": protein_index,\n",
    "                \"sequence\": entry.get(\"sequence\"),\n",
    "                \"exons\": json.dumps(entry.get(\"exons\", [])),\n",
    "                \"protein_coding\": entry.get(\"protein_coding\", False),\n",
    "                \"nmd\": entry.get(\"nmd\", False),\n",
    "                \"pdb_ids\": pdb_ids,\n",
    "                \"pdb_files\": pdb_files\n",
    "            })\n",
    "\n",
    "        conn.commit()\n",
    "\n",
    "    finally:\n",
    "        conn.close()\n",
    "        \n",
    "    print(f\"✅ Inserted {len(data)} proteins with {total_pdbs} total PDB files.\")\n",
    "\n",
    "\n",
    "# Run insert\n",
    "insert_proteins_with_pdbs(engine, data, TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9e4378a-87a6-4508-8c96-4813fb3bd2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_id</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>pdb_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000188938</td>\n",
       "      <td>ENST00000649557</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000188938</td>\n",
       "      <td>ENST00000375412</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000188938</td>\n",
       "      <td>ENST00000423591</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000188938</td>\n",
       "      <td>ENST00000476484</td>\n",
       "      <td>864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000188938</td>\n",
       "      <td>ENST00000428378</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gene_id    transcript_id  pdb_count\n",
       "0  ENSG00000188938  ENST00000649557        810\n",
       "1  ENSG00000188938  ENST00000375412        396\n",
       "2  ENSG00000188938  ENST00000423591        779\n",
       "3  ENSG00000188938  ENST00000476484        864\n",
       "4  ENSG00000188938  ENST00000428378        802"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================================\n",
    "# STEP 5: Verify table content\n",
    "# =========================================\n",
    "df_preview = pd.read_sql(f\"\"\"\n",
    "SELECT gene_id, transcript_id, cardinality(pdb_files) AS pdb_count\n",
    "FROM {TABLE_NAME}\n",
    "ORDER BY gene_id;\n",
    "\"\"\", engine)\n",
    "\n",
    "df_preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ef0a01f-cf63-4744-beed-0db5a3790aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exported 5 proteins (order-preserved and identity-safe)\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# STEP 6: Export full table back to .pkl\n",
    "# =========================================\n",
    "def export_table_to_pkl(engine, table_name, output_path):\n",
    "    \"\"\"\n",
    "    Export entire table back to a .pkl file.\n",
    "    Preserves original PKL order using protein_index.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read from DB using protein_index to preserve order\n",
    "    df = pd.read_sql(\n",
    "        f\"\"\"\n",
    "        SELECT * FROM {table_name}\n",
    "        ORDER BY protein_index\n",
    "        \"\"\",\n",
    "        engine\n",
    "    )\n",
    "\n",
    "    data_out = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # Integrity check: number of PDB IDs matches number of PDB files\n",
    "        assert len(row[\"pdb_ids\"] or []) == len(row[\"pdb_files\"] or [])\n",
    "\n",
    "        protein_entry = {\n",
    "            \"gene_id\": row[\"gene_id\"],\n",
    "            \"transcript_id\": row[\"transcript_id\"],\n",
    "            \"sequence\": row[\"sequence\"],\n",
    "            \"exons\": row[\"exons\"] or [],\n",
    "            \"protein_coding\": row[\"protein_coding\"],\n",
    "            \"nmd\": row[\"nmd\"],\n",
    "            \"pdb_files\": []\n",
    "        }\n",
    "\n",
    "        # Reconstruct PDB files preserving original IDs and content\n",
    "        for pdb_id, pdb_bytes in zip(row[\"pdb_ids\"] or [], row[\"pdb_files\"] or []):\n",
    "            protein_entry[\"pdb_files\"].append({\n",
    "                \"pdb_id\": pdb_id,\n",
    "                \"content\": bytes(pdb_bytes)\n",
    "            })\n",
    "\n",
    "        data_out.append(protein_entry)\n",
    "\n",
    "    # Write back to PKL\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        pickle.dump(data_out, f)\n",
    "\n",
    "    print(f\"✅ Exported {len(data_out)} proteins (order-preserved and identity-safe)\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "OUTPUT_PKL = \"../data/ghazi/ENSG00000188938_export_all_test7.pkl\"\n",
    "export_table_to_pkl(engine, TABLE_NAME, OUTPUT_PKL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4ca46b-a72d-4878-99f9-773b876812b1",
   "metadata": {},
   "source": [
    "# END OF NOTE BOOK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vsl",
   "language": "python",
   "name": "vsl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
